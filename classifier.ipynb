{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import AutoEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "import pandas as pd\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score, f1_score, recall_score, precision_score, accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import seaborn as sns\n",
    "\n",
    "# load from ordered dict\n",
    "# state_dict = torch.load('model.pth')\n",
    "# # load from state dict\n",
    "# model = AutoEncoder()\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "X = data.drop(['Class', 'Amount', 'Time'], axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "X_scale = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# sample data to reduce class imbalance\n",
    "non_fraud_df = X_scale[y == 0][:2000]\n",
    "fraud_df = X_scale[y == 1]\n",
    "\n",
    "X_sample = np.vstack([non_fraud_df, fraud_df])\n",
    "fraud_idx = np.zeros(len(X_sample))\n",
    "fraud_idx[-len(fraud_df):] = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, fraud_idx, test_size=0.2, random_state=42, stratify=fraud_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(X, y, cluster_labels) -> float:\n",
    "    \"\"\"\n",
    "    Function to calculate the purity score. Which is a measure of how well a cluster contains only one class.\n",
    "    It is calculated as the fraction of the dominant class in the cluster. The purity score is then adjusted based on the expected purity.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "    global_class_distribution = y.value_counts(normalize=True).to_dict() # this mihgt be wrong as we are using splits, but they are stratified so it should be okay\n",
    "    # Compute metrics for each cluster, including adjusted purity\n",
    "    cluster_purity = []\n",
    "    cluster_weight = []\n",
    "\n",
    "    for cluster_id in np.unique(cluster_labels):\n",
    "        idx = np.where(cluster_labels == cluster_id)\n",
    "        cluster_data = X[idx]\n",
    "        total_in_cluster = len(cluster_data)\n",
    "        \n",
    "        # Compute class distribution within the cluster\n",
    "        class_distribution = y.iloc[idx].value_counts(normalize=True)\n",
    "        \n",
    "        # Purity: Fraction of the dominant class in the cluster\n",
    "        dominant_class = class_distribution.idxmax()\n",
    "        purity = class_distribution[dominant_class]\n",
    "        \n",
    "        # Expected purity based on global distribution\n",
    "        expected_purity = global_class_distribution[dominant_class]\n",
    "        \n",
    "        # Adjusted Purity\n",
    "        if purity > expected_purity:\n",
    "            adjusted_purity = (purity - expected_purity) / (1 - expected_purity)\n",
    "        else:\n",
    "            adjusted_purity = 0  # Set to 0 if purity is less than or equal to expected purity\n",
    "        \n",
    "        # Weighted purity\n",
    "        cluster_purity.append(adjusted_purity)\n",
    "        cluster_weight.append(total_in_cluster / len(X))\n",
    "    \n",
    "    # Compute the weighted average of cluster purity\n",
    "    purity = np.sum(np.array(cluster_purity) * np.array(cluster_weight))\n",
    "    return purity\n",
    "\n",
    "def score_clustering(X, y, cluster_labels):\n",
    "    return davies_bouldin_score(X, cluster_labels), silhouette_score(X, cluster_labels), purity_score(X, y, cluster_labels)\n",
    "\n",
    "def clustering_classification_report(cluster_labels, class_labels):\n",
    "    \"\"\"\n",
    "    Function to calculate the accuracy of a clustering algorithm.\n",
    "    The accuracy is calculated as the maximum of the purity score and the adjusted purity score.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'cluster': cluster_labels, 'class': class_labels})\n",
    "\n",
    "    # for each cluster find the class that is most common\n",
    "    cluster_class = df.groupby('cluster')['class'].agg(lambda x:x.value_counts().index[0])\n",
    "\n",
    "    # map the cluster labels to the class labels\n",
    "    predicted_class = df['cluster'].map(cluster_class)\n",
    "    # calculate the accuracy\n",
    "    accuracy = accuracy_score(class_labels, predicted_class)\n",
    "    f1 = f1_score(class_labels, predicted_class)\n",
    "    recall = recall_score(class_labels, predicted_class)\n",
    "    precision = precision_score(class_labels, predicted_class)\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'recall': recall,\n",
    "        'precision': precision\n",
    "    }\n",
    "    return metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_kmeans(X_train, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(X_train)\n",
    "    return kmeans\n",
    "\n",
    "def extract_kmeans_cluster_labels(kmeans, X):\n",
    "    return kmeans.predict(X)\n",
    "\n",
    "def format_clustering_metrics(train_scores, test_scores, **kwargs):\n",
    "    results = kwargs\n",
    "    results.update({\n",
    "        'Train_DB': train_scores[0],\n",
    "        'Train_Sil': train_scores[1],\n",
    "        'Train_Pur': train_scores[2],\n",
    "        'Test_DB': test_scores[0],\n",
    "        'Test_Sil': test_scores[1],\n",
    "        'Test_Pur': test_scores[2],\n",
    "    })\n",
    "    return results\n",
    "\n",
    "def format_classification_metrics(train_metrics, test_metrics, **kwargs):\n",
    "    results = kwargs\n",
    "    results.update({\n",
    "        'Train_Acc': train_metrics['accuracy'],\n",
    "        'Train_F1': train_metrics['f1'],\n",
    "        'Train_Recall': train_metrics['recall'],\n",
    "        'Train_Precision': train_metrics['precision'],\n",
    "        'Test_Acc': test_metrics['accuracy'],\n",
    "        'Test_F1': test_metrics['f1'],\n",
    "        'Test_Recall': test_metrics['recall'],\n",
    "        'Test_Precision': test_metrics['precision'],\n",
    "    })\n",
    "    return results\n",
    "\n",
    "def evaluate_kmeans(X_train, X_test, y_train, y_test, n_clusters):\n",
    "    kmeans = fit_kmeans(X_train, n_clusters)\n",
    "    train_cluster_labels = extract_kmeans_cluster_labels(kmeans, X_train)\n",
    "    test_cluster_labels = extract_kmeans_cluster_labels(kmeans, X_test)\n",
    "\n",
    "    train_clustering_scores = score_clustering(X_train, y_train, train_cluster_labels)\n",
    "    test_clustering_scores = score_clustering(X_test, y_test, test_cluster_labels)\n",
    "\n",
    "    train_classification_metrics = clustering_classification_report(train_cluster_labels, y_train)\n",
    "    test_classification_metrics = clustering_classification_report(test_cluster_labels, y_test)\n",
    "    clustering_scores = format_clustering_metrics(train_clustering_scores, test_clustering_scores, n_clusters=n_clusters)\n",
    "    classification_metrics = format_classification_metrics(train_classification_metrics, test_classification_metrics, n_clusters=n_clusters)\n",
    "    return clustering_scores, classification_metrics\n",
    "\n",
    "\n",
    "def score_kmeans(X_train, X_test, y_train, y_test, cluster_counts=None):\n",
    "    if cluster_counts is None:\n",
    "        cluster_counts = [2, 3, 5, 10]\n",
    "    clustering_metrics_list = []\n",
    "    classification_metrics_list = []\n",
    "    for n_clusters in cluster_counts:\n",
    "        clustering_scores, classification_scores = evaluate_kmeans(X_train, X_test, y_train, y_test, n_clusters)\n",
    "        clustering_metrics_list.append(clustering_scores)\n",
    "        classification_metrics_list.append(classification_scores)\n",
    "    return clustering_metrics_list, classification_metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_clusters  Train_DB  Train_Sil  Train_Pur  Test_DB  Test_Sil  Test_Pur\n",
      "0           2      0.84       0.63       0.56     0.79      0.64      0.60\n",
      "1           3      1.09       0.48       0.79     1.05      0.47      0.81\n",
      "2           5      1.97       0.12       0.77     1.93      0.13      0.79\n",
      "3          10      1.96       0.11       0.82     1.74      0.12      0.83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>Train_Acc</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Train_Precision</th>\n",
       "      <th>Test_Acc</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_clusters  Train_Acc  Train_F1  Train_Recall  Train_Precision  Test_Acc  \\\n",
       "0           2       0.91      0.72          0.56             1.00      0.92   \n",
       "1           3       0.96      0.88          0.79             0.99      0.96   \n",
       "2           5       0.95      0.87          0.77             1.00      0.96   \n",
       "3          10       0.96      0.90          0.82             0.99      0.96   \n",
       "\n",
       "   Test_F1  Test_Recall  Test_Precision  \n",
       "0     0.75         0.60            1.00  \n",
       "1     0.89         0.81            0.99  \n",
       "2     0.88         0.79            0.99  \n",
       "3     0.90         0.83            0.99  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_metrics, classification_metrics = score_kmeans(X_train, X_test, y_train, y_test)\n",
    "results_df = pd.DataFrame(cluster_metrics)\n",
    "reports_df = pd.DataFrame(classification_metrics)\n",
    "\n",
    "print(results_df.round(2))\n",
    "reports_df.round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Eps  Train_DB  Train_Sil  Train_Pur  Train_Outliers  Test_DB  Test_Sil  \\\n",
      "0  0.2      1.84       0.28       0.84             342     1.60      0.22   \n",
      "1  0.3      0.78       0.67       0.27             108     0.69      0.68   \n",
      "2  0.4      1.52       0.66       0.22              35     1.09      0.67   \n",
      "\n",
      "   Test_Pur  Test_Outliers  \n",
      "0      0.82             94  \n",
      "1      0.33             34  \n",
      "2      0.26              6  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eps</th>\n",
       "      <th>Train_Acc</th>\n",
       "      <th>Test_Acc</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Train_Precision</th>\n",
       "      <th>Test_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Eps  Train_Acc  Test_Acc  Train_F1  Test_F1  Train_Recall  Test_Recall  \\\n",
       "0  0.2       0.96      0.94      0.89     0.86          0.86         0.85   \n",
       "1  0.3       0.85      0.87      0.42     0.50          0.27         0.33   \n",
       "2  0.4       0.84      0.85      0.35     0.42          0.22         0.26   \n",
       "\n",
       "   Train_Precision  Test_Precision  \n",
       "0             0.93            0.87  \n",
       "1             0.97            0.97  \n",
       "2             0.99            1.00  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def score_dbscan(X_train, X_test, y_train, y_test, eps=None):\n",
    "    if eps is None:\n",
    "        eps = [0.2, 0.3, 0.4]\n",
    "    \n",
    "    clustering_metrics = []\n",
    "    classification_metrics = []\n",
    "\n",
    "    for e in eps:\n",
    "        dbscan = DBSCAN(eps=e, min_samples=20)\n",
    "        dbscan.fit(X_train)\n",
    "        train_clusters = dbscan.labels_\n",
    "\n",
    "        # Assign clusters to test data using nearest neighbors (for DBSCAN)\n",
    "        # This is a way to make predictions on new data, as DBSCAN does not define any cluster centers\n",
    "        # we use the cluster of the nearest core point for each test point\n",
    "        core_samples_mask = dbscan.core_sample_indices_\n",
    "        core_points = X_train[core_samples_mask]\n",
    "\n",
    "        nn = NearestNeighbors(n_neighbors=1).fit(core_points)\n",
    "        distances, indices = nn.kneighbors(X_test)\n",
    "\n",
    "        test_clusters = np.array([dbscan.labels_[core_samples_mask[i]] if distances[j] < dbscan.eps else -1 \n",
    "                                for j, i in enumerate(indices.flatten())])\n",
    "\n",
    "        # These outliers might be considered as a separate cluster\n",
    "        # Count outliers in train and test clusters\n",
    "        train_outliers = np.sum(train_clusters == -1)\n",
    "        test_outliers = np.sum(test_clusters == -1)\n",
    "        # Exclude outliers for scoring\n",
    "        # train_clusters_filtered = train_clusters[train_clusters != -1]\n",
    "        # X_train_filtered = X_train[train_clusters != -1]\n",
    "        # y_train_filtered = y_train[train_clusters != -1]\n",
    "\n",
    "        # test_clusters_filtered = test_clusters[test_clusters != -1]\n",
    "        # X_test_filtered = X_test[test_clusters != -1]\n",
    "        # y_test_filtered = y_test[test_clusters != -1]\n",
    "\n",
    "        # if np.unique(train_clusters_filtered).shape[0] < 2:\n",
    "        #     results.append({\n",
    "        #         'Eps': e,\n",
    "        #         'Train_DB': np.nan,\n",
    "        #         'Train_Sil': np.nan,\n",
    "        #         'Train_Pur': np.nan,\n",
    "        #         'Train_Outliers': train_outliers,\n",
    "        #         'Test_DB': np.nan,\n",
    "        #         'Test_Sil': np.nan,\n",
    "        #         'Test_Pur': np.nan,\n",
    "        #         'Test_Outliers': test_outliers\n",
    "        #     })\n",
    "        # else: \n",
    "        train_scores = score_clustering(X_train, y_train, train_clusters)\n",
    "        test_scores = score_clustering(X_test, y_test, test_clusters)\n",
    "        clustering_metrics.append({\n",
    "            'Eps': e,\n",
    "            'Train_DB': train_scores[0],\n",
    "            'Train_Sil': train_scores[1],\n",
    "            'Train_Pur': train_scores[2],\n",
    "            'Train_Outliers': train_outliers,\n",
    "            'Test_DB': test_scores[0],\n",
    "            'Test_Sil': test_scores[1],\n",
    "            'Test_Pur': test_scores[2],\n",
    "            'Test_Outliers': test_outliers\n",
    "        })\n",
    "\n",
    "        train_classification_report = clustering_classification_report(train_clusters, y_train)\n",
    "        test_classification_report = clustering_classification_report(test_clusters, y_test)\n",
    "\n",
    "        classification_metrics.append({\n",
    "            'Eps': e,\n",
    "            'Train_Acc': train_classification_report['accuracy'],\n",
    "            'Test_Acc': test_classification_report['accuracy'],\n",
    "            'Train_F1': train_classification_report['f1'],\n",
    "            'Test_F1': test_classification_report['f1'],\n",
    "            'Train_Recall': train_classification_report['recall'],\n",
    "            'Test_Recall': test_classification_report['recall'],\n",
    "            'Train_Precision': train_classification_report['precision'],\n",
    "            'Test_Precision': test_classification_report['precision'],\n",
    "        })\n",
    "\n",
    "    return clustering_metrics, classification_metrics\n",
    "\n",
    "dbscan_cluster_metrics, dbscan_classification_metrics = score_dbscan(X_train, X_test, y_train, y_test)\n",
    "dbscan_results_df = pd.DataFrame(dbscan_cluster_metrics)\n",
    "dbscan_reports_df = pd.DataFrame(dbscan_classification_metrics)\n",
    "\n",
    "print(dbscan_results_df.round(2))\n",
    "dbscan_reports_df.round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on dimensionality reduced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0  \\\n",
      "0  {'n_clusters': 2, 'Train_DB': 0.50917173404104...   \n",
      "1  {'n_clusters': 2, 'Train_Acc': 0.9131961866532...   \n",
      "\n",
      "                                                   1  \\\n",
      "0  {'n_clusters': 3, 'Train_DB': 0.63016932674601...   \n",
      "1  {'n_clusters': 3, 'Train_Acc': 0.9573507275464...   \n",
      "\n",
      "                                                   2  \\\n",
      "0  {'n_clusters': 5, 'Train_DB': 0.82322024542433...   \n",
      "1  {'n_clusters': 5, 'Train_Acc': 0.9573507275464...   \n",
      "\n",
      "                                                   3  \n",
      "0  {'n_clusters': 10, 'Train_DB': 0.7415460606238...  \n",
      "1  {'n_clusters': 10, 'Train_Acc': 0.965880582037...  \n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_sample)\n",
    "\n",
    "X_train_pca, X_test_pca, _, _ = train_test_split(X_pca, fraud_idx, test_size=0.2, random_state=42, stratify=fraud_idx)\n",
    "\n",
    "pca_clustering, pca_classification = score_kmeans(X_train_pca, X_test_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   N_clusters  Train_DB  Train_Sil  Train_Pur   Test_DB  Test_Sil  Test_Pur\n",
      "0           2  1.047768   0.381645   0.448394  1.032818  0.382833  0.462359\n",
      "1           3  0.917799   0.405688   0.796482  0.909303  0.418108  0.815682\n",
      "2           4  0.768266   0.454414   0.795188  0.772892  0.453318  0.815682\n",
      "3           5  0.778189   0.437504   0.795188  0.765989  0.425675  0.815682\n",
      "4           6  0.811373   0.435136   0.795188  0.807339  0.434319  0.815682\n",
      "5           7  0.777682   0.435263   0.795188  0.806587  0.425364  0.818576\n",
      "6           8  0.771253   0.432216   0.795188  0.781865  0.431731  0.822585\n",
      "7           9  0.720862   0.456086   0.795188  0.748067  0.440399  0.822585\n",
      "8          10  0.685635   0.465199   0.795188  0.691458  0.459602  0.820581\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X_tsne = tsne.fit_transform(X_sample)\n",
    "\n",
    "X_train_tsne, X_test_tsne, _, _ = train_test_split(X_tsne, fraud_idx, test_size=0.2, random_state=42, stratify=fraud_idx)\n",
    "\n",
    "pca_clustering, pca_classification = score_kmeans(X_train_pca, X_test_pca, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
